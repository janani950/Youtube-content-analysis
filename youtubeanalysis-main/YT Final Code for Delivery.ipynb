{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 265 ms, total: 3.68 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pytube import YouTube\n",
    "import os\n",
    "import youtube_dl\n",
    "import moviepy.editor as mp\n",
    "from mhyt import yt_download\n",
    "import pandas as pd\n",
    "from youtube_dl import YoutubeDL\n",
    "import glob\n",
    "import sys\n",
    "import re\n",
    "import spacy\n",
    "import random\n",
    "import urllib.request\n",
    "import pytube\n",
    "import urllib\n",
    "import numpy as np\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "import time\n",
    "import wave\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import sys\n",
    "import os.path\n",
    "import json\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pafy\n",
    "\n",
    "input1 = pd.read_json('/home/ckpl/Downloads/YouTube_content_analysis/sampleonerequest.json')\n",
    "input1.head()\n",
    "\n",
    "def apipart(url):\n",
    "    APIKEY = \"AIzaSyC4b6O0miZBp4dkFOBQKPLInZdOObfJR_4\"\n",
    "    VideoID = url[url.find(\"https://youtu.be/\")+17:]\n",
    "\n",
    "    params = {'id': VideoID, 'key': APIKEY,\n",
    "          'fields': 'items(id,snippet(channelId,title,categoryId),statistics)',\n",
    "          'part': 'snippet,statistics'}\n",
    "\n",
    "    start = 'https://www.googleapis.com/youtube/v3/videos'\n",
    "\n",
    "    query_string = urllib.parse.urlencode(params)\n",
    "    start = start + \"?\" + query_string\n",
    "\n",
    "    with urllib.request.urlopen(start) as response:\n",
    "        response_text = response.read()\n",
    "        data = json.loads(response_text.decode())\n",
    "    title=data['items'][0]['snippet']['title']\n",
    "    comment=data['items'][0]['statistics']['commentCount']\n",
    "    dislikes=data['items'][0]['statistics']['dislikeCount']\n",
    "    likes=data['items'][0]['statistics']['likeCount']\n",
    "    views=data['items'][0]['statistics']['viewCount']\n",
    "    return (title,comment,dislikes,likes,views)\n",
    "\n",
    "def title(url):\n",
    "    try:\n",
    "        title = apipart(url)[0]\n",
    "        title =  re.sub(r'[^\\w\\s]','',title)\n",
    "    except:\n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            title = re.search('title\":\"(.+?)\"', page.text)\n",
    "            title = title.group(1)\n",
    "            title =  re.sub(r'[^\\w\\s]','',title)\n",
    "        except:\n",
    "            try:\n",
    "                yt_obj = YouTube(url)\n",
    "                title = yt_obj.title\n",
    "                title =  re.sub(r'[^\\w\\s]','',title)\n",
    "            except:\n",
    "                try:\n",
    "                    yt_obj = YouTube(url)\n",
    "                    title =  yt_obj.title\n",
    "                    title =  re.sub(r'[^\\w\\s]','',title)\n",
    "                except:\n",
    "                    try:\n",
    "                        response = requests.get(url).text\n",
    "                        title = re.findall(r'\"title\":\"[^>]*\",',response)[0].split(',')[0][9:-1]\n",
    "                        title =  re.sub(r'[^\\w\\s]','',title)\n",
    "                    except:\n",
    "                        title = 'empty'\n",
    "    return title\n",
    "\n",
    "def rating(url):\n",
    "    try:\n",
    "        rating = re.search('averageRating\":(.+?),', page.text)\n",
    "        rating = rating.group(1)\n",
    "    except:\n",
    "        try:\n",
    "            yt_obj = pafy.new(url)\n",
    "            rating = yt_obj.rating\n",
    "        except:\n",
    "            try:\n",
    "                yt_obj = YouTube(url)\n",
    "                rating = yt_obj.rating\n",
    "            except Exception as e:\n",
    "                rating = e     \n",
    "    return rating\n",
    "\n",
    "def views(url):\n",
    "    try:\n",
    "        views = apipart(url)[4]\n",
    "    except:\n",
    "        try:\n",
    "            yt_obj = pafy.new(url)\n",
    "            views = yt_obj.viewcount\n",
    "        except:\n",
    "            try:\n",
    "                views =  re.search('viewCount\":\"(.+?)\"', page.text)\n",
    "                views =  views.group(1)\n",
    "            except:\n",
    "                try:\n",
    "                    yt_obj = YouTube(url)\n",
    "                    views = yt_obj.views\n",
    "                except Exception as e:\n",
    "                    views = e               \n",
    "    return views\n",
    "\n",
    "def author(url):\n",
    "    try:\n",
    "        yt_obj = pafy.new(url)\n",
    "        author = yt_obj.author\n",
    "    except:\n",
    "        try:\n",
    "            author = re.search('author\":\"(.+?)\"', page.text)\n",
    "            author = author.group(1)\n",
    "        except:\n",
    "            try:\n",
    "                yt_obj = YouTube(url)\n",
    "                author = yt_obj.author\n",
    "            except Exception as e:\n",
    "                author = e               \n",
    "    return author\n",
    "\n",
    "def key(url):\n",
    "    try:\n",
    "        yt_obj = pafy.new(url)\n",
    "        key = yt_obj.videoid\n",
    "    except:\n",
    "        try:\n",
    "            key = url[url.find(\"https://youtu.be/\")+17:]\n",
    "        except Exception as e:\n",
    "            key = e   \n",
    "    return key\n",
    "\n",
    "def duration(url):\n",
    "    try:\n",
    "        yt_obj = pafy.new(url)\n",
    "        duration = yt_obj.duration\n",
    "    except Exception as e:\n",
    "        duration = e\n",
    "    return duration\n",
    "\n",
    "def comment(url):\n",
    "    try:\n",
    "        comment = apipart(url)[1]\n",
    "    except Exception as e:\n",
    "        comment = e\n",
    "    return comment\n",
    "\n",
    "def dislikes(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        dislikes = re.search('dislike this video along with (.+?) other people', page.text)\n",
    "        dislikes = dislikes.group(1)\n",
    "    except:\n",
    "        try:\n",
    "            dislikes = apipart(url)[2]   \n",
    "        except Exception as e:\n",
    "            dislikes = e\n",
    "    return dislikes\n",
    "\n",
    "\n",
    "def likes(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        likes = re.search('like this video along with (.+?) other people', page.text)\n",
    "        likes = likes.group(1)\n",
    "    except:\n",
    "        try:\n",
    "            likes = apipart(url)[3]\n",
    "        except Exception as e:\n",
    "            likes = e\n",
    "    return likes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def date(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        date = re.search('datePublished\" content=\"(.+?)\">', page.text)\n",
    "        date = date.group(1)\n",
    "    except Exception as e:\n",
    "        date = e\n",
    "    return date\n",
    "\n",
    "def subscriber(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        channelid = re.search('channelId\":\"(.+?)\"', page.text)\n",
    "        chanid = channelid.group(1)\n",
    "        key=\"AIzaSyC4b6O0miZBp4dkFOBQKPLInZdOObfJR_4\"\n",
    "        data=urllib.request.urlopen(\"https://www.googleapis.com/youtube/v3/channels?part=statistics&id=\"+chanid+\"&key=\"+key).read()\n",
    "        subs=json.loads(data)\n",
    "        subscriber = subs[\"items\"][0][\"statistics\"][\"subscriberCount\"]\n",
    "    except Exception as e:\n",
    "        subscriber = e\n",
    "    return subscriber\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "input1['comment']   = input1['url'].apply(lambda x : comment(x))\n",
    "input1['date']    = input1['url'].apply(lambda x : date(x))\n",
    "input1['likes']   = input1['url'].apply(lambda x : likes(x))\n",
    "input1['dislikes']= input1['url'].apply(lambda x : dislikes(x))\n",
    "input1['duration']= input1['url'].apply(lambda x : duration(x))\n",
    "input1['key']     = input1['url'].apply(lambda x : key(x))\n",
    "input1['author']  = input1['url'].apply(lambda x : author(x))\n",
    "input1['views']   = input1['url'].apply(lambda x : views(x))\n",
    "input1['title']   = input1['url'].apply(lambda x : title(x))\n",
    "input1['rating']  = input1['url'].apply(lambda x : rating(x))\n",
    "input1['subscriber']   = input1['url'].apply(lambda x : subscriber(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 634 ms, sys: 168 ms, total: 802 ms\n",
      "Wall time: 5.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "VidDir=\"/home/ckpl/Downloads/YouTube_content_analysis/directory\"\n",
    "def file_base_name(file_name):\n",
    "    if '.' in file_name:\n",
    "        separator_index = file_name.index('.')\n",
    "        base_name = file_name[:separator_index]\n",
    "        return base_name\n",
    "    else:\n",
    "        return file_name\n",
    "def path_base_name(VidDir):\n",
    "    file_name = os.path.basename(VidDir)\n",
    "    return file_base_name(file_name)\n",
    "for index,row in input1.iterrows():\n",
    "    if(os.path.exists(VidDir+'/'+row['title']+'.mp4') is False):  \n",
    "        try:\n",
    "            def downloadYouTube(url, path):\n",
    "                yt = YouTube(url)\n",
    "                yt = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                filename = yt.download(path)\n",
    "                title = path_base_name(filename)\n",
    "                return title\n",
    "            title = downloadYouTube(row['url'], VidDir)\n",
    "            input1.at[0,'vidstatus'] = 'success'\n",
    "            if (row['title'] is 'empty'):\n",
    "                row['title'] = title\n",
    "        except:\n",
    "            try:\n",
    "                def dwnldutube(url,VidDir):\n",
    "                    filename=YouTube(url).streams.first().download(VidDir)\n",
    "                    title=path_base_name(filename)\n",
    "                    return title\n",
    "                title = dwnldutube(row['url'],VidDir)\n",
    "                input1.at[0,'vidstatus'] = 'success'\n",
    "                if (row['title'] is 'empty'):\n",
    "                    row['title'] = title\n",
    "            except:\n",
    "                try:\n",
    "                    filename = pytube.YouTube(row['url']).streams.get_highest_resolution().download(VidDir)\n",
    "                    title = path_base_name(filename)\n",
    "                    input1.at[0,'vidstatus'] = 'success'\n",
    "                    if (row['title'] is 'empty'):\n",
    "                        row['title'] = title\n",
    "                except:\n",
    "                    try:\n",
    "                        def pafyvid(url,VidDir):\n",
    "                            video = pafy.new(url) \n",
    "                            streams = video.streams \n",
    "                            best = video.getbest(preftype =\"mp4\") \n",
    "                            best.download(VidDir) \n",
    "                            title = video.title\n",
    "                            return title\n",
    "                        title = pafyvid(row['url'],VidDir)\n",
    "                        input1.at[0,'vidstatus'] = 'success'\n",
    "                        input1.at[0,'title'] = title                    \n",
    "                    except:\n",
    "                        try:\n",
    "                            def mhyt_ydl(url,VidDir,title):\n",
    "                                title = title+'.mp4'\n",
    "                                ydl_opts = {\n",
    "                                    'outtmpl': os.path.join(VidDir,title)\n",
    "                                }\n",
    "\n",
    "                                yt_download(url,video_format='mp4',ismucic=True,**ydl_opts)\n",
    "                            mhyt_ydl(row['url'],VidDir,row['title'])\n",
    "                            input1.at[0,'vidstatus'] = 'success'                        \n",
    "                        except Exception as e:\n",
    "                            input1.at[0,'vidstatus'] = e\n",
    "    else:\n",
    "        input1.at[0,'vidstatus'] = 'vid already exist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incase utube says : unable to fetch video data or regex pattern doesn't match then,\n",
    "# try to clear cache and run again or \n",
    "# try to upgrade pytube bcoz sometimes google ll change their regex pattern or\n",
    "# after clearing cache and  after upgrading pytube try to run same url after some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "chunk:   0%|          | 0/5423 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    success\n",
      "Name: vidstatus, dtype: object\n",
      "MoviePy - Writing audio in /home/ckpl/Downloads/YouTube_content_analysis/directory/How To Get Clear Glowing Skin Naturally For Men  Skin Care Tips.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "CPU times: user 13.4 s, sys: 4.74 s, total: 18.1 s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in input1['title']:\n",
    "    if input1.at[0,'vidstatus'] is 'success':\n",
    "        print(input1['vidstatus'])\n",
    "        file = VidDir+'/'+i+'.mp4'\n",
    "        if(os.path.exists(VidDir+'/'+i+'.wav') is False):\n",
    "            try:\n",
    "                def aud(file):\n",
    "                    video=mp.VideoFileClip(file)\n",
    "                    newfile=file[:-4]\n",
    "                    audio = video.audio.write_audiofile(newfile+\".wav\")\n",
    "                    title = path_base_name(file)\n",
    "                    return title\n",
    "                title = aud(file)\n",
    "                input1.at[0,'audstatus'] = 'success'\n",
    "                \n",
    "                def concatenate_list_data(list):\n",
    "                    result= ''\n",
    "                    for element in list:\n",
    "                        result += str(element)\n",
    "                    return result   \n",
    "\n",
    "                def processed_text(list):\n",
    "                    result=''\n",
    "                    for element in list:\n",
    "                        result = re.sub(r'[^\\w\\s]',' ',element)\n",
    "                        result = re.sub(r'\\d+', '', result)\n",
    "                        result = result.lower().strip()\n",
    "                        result = re.sub('\\s+',' ',result)\n",
    "                    return result\n",
    "\n",
    "                def ing(text,prdnlp):   \n",
    "                    result=''\n",
    "                    for model in prdnlp:\n",
    "                        for element in text:\n",
    "                            doc = model(str(element))\n",
    "                            op = {ent.text for ent in doc.ents}\n",
    "                            op = ', '.join(op)\n",
    "                            temp = \",\"\n",
    "                            result+=op+temp\n",
    "                    result=result[:-1]\n",
    "                    each=result.split(\",\")\n",
    "                    result = [x.strip(' ') for x in each]\n",
    "                    result = set(result)\n",
    "                    result = ', '.join(result) #optional convert to str\n",
    "                    return result\n",
    "\n",
    "                def speech_recognize_continuous_from_file(file):\n",
    "                    \"\"\"performs continuous speech recognition with input from an audio file\"\"\"\n",
    "                    # <SpeechContinuousRecognitionWithFile>\n",
    "                    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "                    speech_config.endpoint_id = EndpointId\n",
    "                    audio_config = speechsdk.audio.AudioConfig(filename=file)\n",
    "\n",
    "                    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "                    done = False\n",
    "\n",
    "                    def stop_cb(evt):\n",
    "                        \"\"\"callback that stops continuous recognition upon receiving an event `evt`\"\"\"\n",
    "                        #print('CLOSING on {}'.format(evt))\n",
    "                        speech_recognizer.stop_continuous_recognition()\n",
    "                        nonlocal done\n",
    "                        done = True\n",
    "\n",
    "                    all_results = []\n",
    "                    def handle_final_result(evt):\n",
    "                        all_results.append(evt.result.text)\n",
    "\n",
    "                    speech_recognizer.recognized.connect(handle_final_result)\n",
    "                    # Connect callbacks to the events fired by the speech recognizer\n",
    "                    speech_recognizer.recognizing.connect(lambda evt: 'RECOGNIZING: {}'.format(evt))\n",
    "                    speech_recognizer.recognized.connect(lambda evt: 'RECOGNIZED: {}'.format(evt))\n",
    "                    speech_recognizer.session_started.connect(lambda evt: 'SESSION STARTED: {}'.format(evt))\n",
    "                    speech_recognizer.session_stopped.connect(lambda evt: 'SESSION STOPPED {}'.format(evt))\n",
    "                    speech_recognizer.canceled.connect(lambda evt: 'CANCELED {}'.format(evt))\n",
    "                    # stop continuous recognition on either session stopped or canceled events\n",
    "                    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "                    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "                    # Start continuous speech recognition\n",
    "                    speech_recognizer.start_continuous_recognition()\n",
    "                    while not done:\n",
    "                        time.sleep(.5)    \n",
    "                    return all_results\n",
    "                speech_key, service_region = \"0f95674905f94c32abfe87a2679aa37d\", \"eastus\"\n",
    "                EndpointId=\"a1679626-4779-43ba-8c6a-876722f5601f\"\n",
    "                prdnlp =[spacy.load('/home/ckpl/Downloads/utube_en_ing/prdnlpNov06'),spacy.load('/home/ckpl/Downloads/utube_en_ing/prdnlpNov18'),spacy.load('/home/ckpl/Downloads/utube_en_ing/prdnlpNov25'),spacy.load('/home/ckpl/Downloads/utube_en_ing/prdnlpNov29')]\n",
    "                \n",
    "                if input1.at[0,'audstatus'] is 'success':\n",
    "                    text_list=[]\n",
    "                    temp = [speech_recognize_continuous_from_file(VidDir+'/'+i+'.wav')  if (os.path.exists(VidDir+'/'+i+'.wav')) is True else 'notexist'  for i in input1['title']]\n",
    "                    for i in range(0,len(temp)):\n",
    "                            text_list.append(concatenate_list_data(temp[i]))\n",
    "                    input1.at[0,'text']=text_list\n",
    "                    input1['processedtext']=processed_text(input1['text'])\n",
    "                    input1.at[0,'ing']= ing(input1['processedtext'],prdnlp)\n",
    "            except OSError as e:\n",
    "                 input1.at[0,'audstatus'] = e\n",
    "        else:\n",
    "            input1.at[0,'audstatus'] = 'aud already exist'\n",
    "    else:\n",
    "        print(input1['vidstatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if aud threws os error - then , url is invalid  or\n",
    "#if .mp4 not found in VidDir \n",
    "#clear cache and after sometime pass the same url again to download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>div</th>\n",
       "      <th>dept</th>\n",
       "      <th>claims</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>duration</th>\n",
       "      <th>key</th>\n",
       "      <th>author</th>\n",
       "      <th>views</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>subscriber</th>\n",
       "      <th>vidstatus</th>\n",
       "      <th>audstatus</th>\n",
       "      <th>text</th>\n",
       "      <th>processedtext</th>\n",
       "      <th>ing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https://youtu.be/Q8OJGd54B9Q</td>\n",
       "      <td>facepack</td>\n",
       "      <td>skincare</td>\n",
       "      <td>best face glow pack</td>\n",
       "      <td>760</td>\n",
       "      <td>2018-10-14</td>\n",
       "      <td>25,452</td>\n",
       "      <td>1327</td>\n",
       "      <td>00:04:06</td>\n",
       "      <td>Q8OJGd54B9Q</td>\n",
       "      <td>TARUN MOLRI</td>\n",
       "      <td>1015796</td>\n",
       "      <td>How To Get Clear Glowing Skin Naturally For Me...</td>\n",
       "      <td>4.801785</td>\n",
       "      <td>83400</td>\n",
       "      <td>success</td>\n",
       "      <td>success</td>\n",
       "      <td>So my skin used to look like this. Now it look...</td>\n",
       "      <td>so my skin used to look like this now it look ...</td>\n",
       "      <td>water, rose, green tea, wake, rose water, lemo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            url       div      dept               claims  \\\n",
       "0  https://youtu.be/Q8OJGd54B9Q  facepack  skincare  best face glow pack   \n",
       "\n",
       "  comment        date   likes dislikes  duration          key       author  \\\n",
       "0     760  2018-10-14  25,452     1327  00:04:06  Q8OJGd54B9Q  TARUN MOLRI   \n",
       "\n",
       "     views                                              title    rating  \\\n",
       "0  1015796  How To Get Clear Glowing Skin Naturally For Me...  4.801785   \n",
       "\n",
       "  subscriber vidstatus audstatus  \\\n",
       "0      83400   success   success   \n",
       "\n",
       "                                                text  \\\n",
       "0  So my skin used to look like this. Now it look...   \n",
       "\n",
       "                                       processedtext  \\\n",
       "0  so my skin used to look like this now it look ...   \n",
       "\n",
       "                                                 ing  \n",
       "0  water, rose, green tea, wake, rose water, lemo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end dataframe can b dumped into json \n",
    "input1.to_json(VidDir+'/'+'output.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total run time 2mins 26seconds:\n",
    "#scrap part - 6.84s\n",
    "#vid xtract part - 4.25s\n",
    "#aud xtract & azure txt & ing part - 2min 15s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
