{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 986 ms, sys: 223 ms, total: 1.21 s\n",
      "Wall time: 950 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#downloading video using pytube\n",
    "from pytube import YouTube\n",
    "#directory\n",
    "import os\n",
    "#converting video to audio using moviepy\n",
    "import moviepy.editor as mp\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in specified directory all conversion will be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VidDir=\"/home/ckpl/Downloads/Voice2txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing all VidLink in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        VidLink\n",
      "0  https://youtu.be/ZxKfQVxlE9w\n"
     ]
    }
   ],
   "source": [
    "data={'VidLink':['https://youtu.be/ZxKfQVxlE9w']}\n",
    "#data = {'VidLink':  ['https://youtu.be/NNOZ-cjsAT0','https://youtu.be/QsynaMuQhZg','https://youtu.be/Q8OJGd54B9Q','https://youtu.be/HhcRV2Fe3Fg', 'https://youtu.be/rITo2zDNM8M','https://youtu.be/rITo2zDNM8M','https://youtu.be/PH9z9LdjQFk','https://youtu.be/fQypGNWCYbs','https://youtu.be/0nBzGIxJEtM','https://youtu.be/C38iGUSvBCA','https://youtu.be/NQzAEBNwC3k']}\n",
    "df = pd.DataFrame (data, columns = ['VidLink'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# youtube key will be extracted from the youtube link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key']=''\n",
    "df['key']= df['VidLink'].apply(lambda x: x[x.find(\"https://youtu.be/\")+17:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "for i in df['VidLink']: \n",
    "    try:\n",
    "        yt_obj = YouTube(i)\n",
    "        #df['Title']=yt_obj.title\n",
    "        print(f'Title:{yt_obj.title}')\n",
    "        #print(f'Length:{yt_obj.length}')\n",
    "        #print(f'Rating:{yt_obj.rating}')\n",
    "        #print(f'ViewsCount:{yt_obj.views}')\n",
    "        #print(f'Author:{yt_obj.author}')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for download vid,aud convert,concate str in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1e+03 ns, total: 8 µs\n",
      "Wall time: 10.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element)\n",
    "    return result\n",
    "\n",
    "def downloadYouTube(videourl, path):\n",
    "    #DownloadYoutube\n",
    "    yt = YouTube(videourl)\n",
    "    yt = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    yt.download(path)\n",
    "\n",
    "def Video2Audio():\n",
    "    vidset = [file for file in glob.glob(VidDir + \"**/*.mp4\", recursive=True)]\n",
    "    for file in vidset:\n",
    "        video=mp.VideoFileClip(file)\n",
    "        newfile=file[:-4]\n",
    "        video.audio.write_audiofile(newfile+\".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing entire VidLink for conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   4%|▍         | 255/6528 [00:00<00:02, 2451.13it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in /home/ckpl/Downloads/Voice2txt/2 Simple Face Mask For Glowing And Ageless Skin.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 0/11767 [00:00<?, ?it/s, now=None]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /home/ckpl/Downloads/Voice2txt/Top 5 HAIR CARE Tips for Indian Men  Mens Hair Care Routine  BeerBiceps Grooming.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 0/4658 [00:00<?, ?it/s, now=None]               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /home/ckpl/Downloads/Voice2txt/Skin Whitening Tomato Facial  Get Fair Glowing Spotless Skin Permanently.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 0/717 [00:00<?, ?it/s, now=None]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /home/ckpl/Downloads/Voice2txt/Clean & Clears Foaming Face Wash (English).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 0/15342 [00:00<?, ?it/s, now=None]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /home/ckpl/Downloads/Voice2txt/The secret to my GLOWING skin  Product Review  Chetali Chadha.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "CPU times: user 14.3 s, sys: 979 ms, total: 15.3 s\n",
      "Wall time: 24.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#link to video conversion\n",
    "for i in  df['VidLink']:\n",
    "    downloadYouTube(i,VidDir)\n",
    "#vidtoaud conversion\n",
    "Video2Audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# std custom endpoint,speech key,region r passed in variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import wave\n",
    "try:\n",
    "    import azure.cognitiveservices.speech as speechsdk\n",
    "except ImportError:\n",
    "    print(\"\"\"\n",
    "    Importing the Speech SDK for Python failed.\n",
    "    Refer to\n",
    "    https://docs.microsoft.com/azure/cognitive-services/speech-service/quickstart-python for\n",
    "    installation instructions.\n",
    "    \"\"\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "speech_key, service_region = \"0f95674905f94c32abfe87a2679aa37d\", \"eastus\"\n",
    "\n",
    "EndpointId=\"a1679626-4779-43ba-8c6a-876722f5601f\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for continous speech recognisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def speech_recognize_continuous_from_file(file):\n",
    "    \"\"\"performs continuous speech recognition with input from an audio file\"\"\"\n",
    "    # <SpeechContinuousRecognitionWithFile>\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.endpoint_id = EndpointId\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=file)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    done = False\n",
    "\n",
    "    def stop_cb(evt):\n",
    "        \"\"\"callback that stops continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        #print('CLOSING on {}'.format(evt))\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    all_results = []\n",
    "    def handle_final_result(evt):\n",
    "        all_results.append(evt.result.text)\n",
    "        \n",
    "    speech_recognizer.recognized.connect(handle_final_result)\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognizing.connect(lambda evt: 'RECOGNIZING: {}'.format(evt))\n",
    "    speech_recognizer.recognized.connect(lambda evt: 'RECOGNIZED: {}'.format(evt))\n",
    "    speech_recognizer.session_started.connect(lambda evt: 'SESSION STARTED: {}'.format(evt))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: 'SESSION STOPPED {}'.format(evt))\n",
    "    speech_recognizer.canceled.connect(lambda evt: 'CANCELED {}'.format(evt))\n",
    "    # stop continuous recognition on either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(.5)    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop to call function to convert audio files to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "output_list = []\n",
    "\n",
    "fileset = [file for file in glob.glob(VidDir + \"**/*.wav\", recursive=True)]\n",
    "temp = [speech_recognize_continuous_from_file(file) for file in fileset]\n",
    "\n",
    "for i in range(0,len(temp)):\n",
    "    output_list.append(concatenate_list_data(temp[i]))\n",
    "    \n",
    "output_df = pd.DataFrame(output_list,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[x for x in output_df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing the text to ingredient model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-existing spacy model\n",
    "import spacy\n",
    "import re\n",
    "prdnlp=spacy.load('/home/ckpl/Downloads/utube_en_ing/prdnlpOct20')\n",
    "\n",
    "# Getting the pipeline component\n",
    "#ner=nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our trained Model\n",
    "modelfile = \"prdnlp\"\n",
    "prdnlp.to_disk(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df=pd.read_csv(\"output_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required attribute - dashboard\n",
    "del output_df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = output_df[['text']].copy()\n",
    "output_df['text']=output_df['text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "output_df['text']=[x for x in output_df['text'].str.lower().str.strip()]\n",
    "output_df['text']=output_df['text'].apply(lambda x : (re.sub('\\s+',' ',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['ing']=\"\"\n",
    "for index,row in output_df.iterrows():\n",
    "    doc=prdnlp(row['text'])\n",
    "    row['ing']={ent.text for ent in doc.ents}\n",
    "    output_df['ing'].append(print(row['ing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting filename for Title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def file_base_name(file_name):\n",
    "    if '.' in file_name:\n",
    "        separator_index = file_name.index('.')\n",
    "        base_name = file_name[:separator_index]\n",
    "        return base_name\n",
    "    else:\n",
    "        return file_name\n",
    "\n",
    "def path_base_name(VidDir):\n",
    "    file_name = os.path.basename(VidDir)\n",
    "    return file_base_name(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_text={'title':[]}\n",
    "fileset = [file for file in glob.glob(VidDir + \"**/*.wav\", recursive=True)]\n",
    "for file in fileset:\n",
    "    parsed_text['title'].append(path_base_name(file))\n",
    "output_df['Title']=parsed_text['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['VidLink']: \n",
    "    try:\n",
    "        yt_obj = YouTube(i)\n",
    "        print(f'Title:{yt_obj.title}')\n",
    "        print(f'Length:{yt_obj.length}')\n",
    "        print(f'Rating:{yt_obj.rating}')\n",
    "        print(f'ViewsCount:{yt_obj.views}')\n",
    "        print(f'Author:{yt_obj.author}')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from typing import List\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import swagger_client as cris_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, format=\"%(message)s\")\n",
    "\n",
    "SUBSCRIPTION_KEY = \"891818643be44c078a57ee2ced246297\"\n",
    "\n",
    "HOST_NAME = \"westeurope.cris.ai\"\n",
    "PORT = 443\n",
    "\n",
    "NAME = \"Simple transcription\"\n",
    "DESCRIPTION = \"Simple transcription description\"\n",
    "\n",
    "LOCALE = \"en-IN\"\n",
    "RECORDINGS_BLOB_URI = \"/home/ckpl/Documents/multi.wav\"\n",
    "# ADAPTED_ACOUSTIC_ID = None  # guid of a custom acoustic model\n",
    "# ADAPTED_LANGUAGE_ID = None  # guid of a custom language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe():\n",
    "    logging.info(\"Starting transcription client...\")\n",
    "\n",
    "    # configure API key authorization: subscription_key\n",
    "    configuration = cris_client.Configuration()\n",
    "    configuration.api_key['Ocp-Apim-Subscription-Key'] = SUBSCRIPTION_KEY\n",
    "\n",
    "    # create the client object and authenticate\n",
    "    client = cris_client.ApiClient(configuration)\n",
    "\n",
    "    # create an instance of the transcription api class\n",
    "    transcription_api = cris_client.CustomSpeechTranscriptionsApi(api_client=client)\n",
    "\n",
    "    # get all transcriptions for the subscription\n",
    "    transcriptions: List[cris_client.Transcription] = transcription_api.get_transcriptions()\n",
    "\n",
    "    logging.info(\"Deleting all existing completed transcriptions.\")\n",
    "\n",
    "    # delete all pre-existing completed transcriptions\n",
    "    # if transcriptions are still running or not started, they will not be deleted\n",
    "    for transcription in transcriptions:\n",
    "        transcription_api.delete_transcription(transcription.id)\n",
    "\n",
    "    logging.info(\"Creating transcriptions.\")\n",
    "\n",
    "    # transcription definition using custom models\n",
    "#     transcription_definition = cris_client.TranscriptionDefinition(\n",
    "#         name=NAME, description=DESCRIPTION, locale=LOCALE, recordings_url=RECORDINGS_BLOB_URI,\n",
    "#         models=[cris_client.ModelIdentity(ADAPTED_ACOUSTIC_ID), cris_client.ModelIdentity(ADAPTED_LANGUAGE_ID)]\n",
    "#     )\n",
    "\n",
    "    # comment out the previous statement and uncomment the following to use base models for transcription\n",
    "    transcription_definition = cris_client.TranscriptionDefinition(\n",
    "         name=NAME, description=DESCRIPTION, locale=LOCALE, recordings_url=RECORDINGS_BLOB_URI\n",
    "     )\n",
    "\n",
    "    data, status, headers = transcription_api.create_transcription_with_http_info(transcription_definition)\n",
    "\n",
    "    # extract transcription location from the headers\n",
    "    transcription_location: str = headers[\"location\"]\n",
    "\n",
    "    # get the transcription Id from the location URI\n",
    "    created_transcriptions = list()\n",
    "    created_transcriptions.append(transcription_location.split('/')[-1])\n",
    "\n",
    "    logging.info(\"Checking status.\")\n",
    "\n",
    "    completed, running, not_started = 0, 0, 0\n",
    "\n",
    "    while completed < 1:\n",
    "        # get all transcriptions for the user\n",
    "        transcriptions: List[cris_client.Transcription] = transcription_api.get_transcriptions()\n",
    "\n",
    "        # for each transcription in the list we check the status\n",
    "        for transcription in transcriptions:\n",
    "            if transcription.status == \"Failed\" or transcription.status == \"Succeeded\":\n",
    "                # we check to see if it was one of the transcriptions we created from this client\n",
    "                if transcription.id not in created_transcriptions:\n",
    "                    continue\n",
    "\n",
    "                completed += 1\n",
    "\n",
    "                if transcription.status == \"Succeeded\":\n",
    "                    results_uri = transcription.results_urls[\"channel_0\"]\n",
    "                    results = requests.get(results_uri)\n",
    "                    logging.info(\"Transcription succeeded. Results: \")\n",
    "                    logging.info(results.content.decode(\"utf-8\"))\n",
    "            elif transcription.status == \"Running\":\n",
    "                running += 1\n",
    "            elif transcription.status == \"NotStarted\":\n",
    "                not_started += 1\n",
    "\n",
    "        logging.info(f\"Transcriptions status: {completed} completed, {running} running, {not_started} not started yet\")\n",
    "        # wait for 5 seconds\n",
    "        time.sleep(5)\n",
    "\n",
    "    input(\"Press any key...\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    transcribe()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue to fix\n",
    "#when compared with google/azure python continous/azure front page js speech to txt app\n",
    "#azure front page js speech to txt app gives better good output\n",
    "#so wanna improve the accuracy as lyk in azure app\n",
    "#diarization is a property used to identify different speakers in a txt in batch (how to add wanna c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
